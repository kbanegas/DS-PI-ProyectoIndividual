{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\karen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\karen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Procesamiento\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import missingno as msno\n",
    " \n",
    "#Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import io\n",
    "import glob\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Esto sirve para configurar NLTK. La primera vez puede tardar un poco\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_ratio_and_distance(s, t, ratio_calc = False):\n",
    "    \"\"\" levenshtein_ratio_and_distance:\n",
    "        Esta función calcula la distancia de Levenshtein entre dos cadenas de caracteres\n",
    "        Si ratio_calc = True, la función computa la distancia de Levenshtein o similaridad entre dos cadenas de caracteres\n",
    "        Para todas las 'i' y 'j', distance[i,j] contendrá la distancia de Levenshtein entre los primeros 'i' caracteres de 's'\n",
    "        y el primer 'j' de 't'\n",
    "        Fuente: https://www.datacamp.com/community/tutorials/fuzzy-string-python\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    # Initialize matrix of zeros\n",
    "    s = str(s)\n",
    "    t = str(t)\n",
    "    rows = len(s)+1\n",
    "    cols = len(t)+1\n",
    "    if (rows == 1 | cols == 1):\n",
    "        return 0\n",
    "    col = 0\n",
    "    row = 0\n",
    "    distance = np.zeros((rows,cols),dtype = int)\n",
    "\n",
    "    # Populate matrix of zeros with the indeces of each character of both strings\n",
    "    for i in range(1, rows):\n",
    "        for k in range(1,cols):\n",
    "            distance[i][0] = i\n",
    "            distance[0][k] = k\n",
    "\n",
    "    # Iterate over the matrix to compute the cost of deletions,insertions and/or substitutions    \n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            if s[row-1] == t[col-1]:\n",
    "                cost = 0 # If the characters are the same in the two strings in a given position [i,j] then the cost is 0\n",
    "            else:\n",
    "                # In order to align the results with those of the Python Levenshtein package, if we choose to calculate the ratio\n",
    "                # the cost of a substitution is 2. If we calculate just distance, then the cost of a substitution is 1.\n",
    "                if ratio_calc == True:\n",
    "                    cost = 2\n",
    "                else:\n",
    "                    cost = 1\n",
    "            distance[row][col] = min(distance[row-1][col] + 1,      # Cost of deletions\n",
    "                                 distance[row][col-1] + 1,          # Cost of insertions\n",
    "                                 distance[row-1][col-1] + cost)     # Cost of substitutions\n",
    "    if ratio_calc == True:\n",
    "        # Computation of the Levenshtein Distance Ratio\n",
    "        Ratio = ((len(s)+len(t)) - distance[row][col]) / (len(s)+len(t))\n",
    "        return Ratio\n",
    "    else:\n",
    "        # print(distance) # Uncomment if you want to see the matrix showing how the algorithm computes the cost of deletions,\n",
    "        # insertions and/or substitutions\n",
    "        # This is the minimum number of edits needed to convert string a to string b\n",
    "        return \"Las cadenas de caracteres están a {} ediciones de distancia\".format(distance[row][col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karen\\AppData\\Local\\Temp\\ipykernel_2092\\468490639.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df0.sort_values('ID', inplace= True)\n",
      "C:\\Users\\karen\\AppData\\Local\\Temp\\ipykernel_2092\\468490639.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2.sort_values('ID', inplace= True)\n",
      "C:\\Users\\karen\\AppData\\Local\\Temp\\ipykernel_2092\\468490639.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfn.sort_values('ID', inplace= True)\n",
      "C:\\Users\\karen\\AppData\\Local\\Temp\\ipykernel_2092\\468490639.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfn1.sort_values('ID', inplace= True)\n",
      "C:\\Users\\karen\\AppData\\Local\\Temp\\ipykernel_2092\\468490639.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfn2.sort_values('ID', inplace= True)\n"
     ]
    }
   ],
   "source": [
    "#lectura y concatenacion de archivos del cliente en la carpeta Datasets   \n",
    "df_Ucliente =[]\n",
    "for csv in sorted(glob.glob('Datasets/Cli*.csv')):\n",
    "    #print(csv)\n",
    "    df= pd.read_csv(csv, sep=\";\", decimal=\".\",encoding=\"utf-8\")\n",
    "    df_Ucliente.append(df)\n",
    "df_Cliente= pd.concat(df_Ucliente)\n",
    "#df_Cliente.head()\n",
    "#ordena por ID\n",
    "df_Cliente.sort_values('ID', inplace= True)\n",
    "#Elimina columna\n",
    "df_Cliente.drop(['col10'], axis=1, inplace=True)\n",
    "#Crea df de valores nulos en nombre e ID y los ordena por ID, concatenandolos\n",
    "df0= df_Cliente[df_Cliente['ID'].isnull()]\n",
    "df0.sort_values('ID', inplace= True)\n",
    "df2= df_Cliente[df_Cliente['Nombre_y_Apellido'].isnull()]\n",
    "df2.sort_values('ID', inplace= True)\n",
    "df= pd.concat([df0,df2], axis=0)\n",
    "#los lleva a un csv auxiliar antes de eliminarlos\n",
    "df.to_csv(\"Datasets/AuxiliarClientes.csv\")\n",
    "#Rellena valores personales con Sin dato\n",
    "df_Cliente.fillna({'Provincia': 'Sin dato'}, inplace=True)\n",
    "df_Cliente.fillna({'Domicilio': 'Sin dato'}, inplace=True)\n",
    "df_Cliente.fillna({'Telefono': 'Sin dato'}, inplace=True)\n",
    "df_Cliente.fillna({'Edad': 0}, inplace=True)\n",
    "#Remplaza coma por punto en valores de X y Y, elimina espacios en blanco\n",
    "df_Cliente['X'] = df_Cliente['X'].str.replace(\",\", \".\")#.astype(float)\n",
    "df_Cliente['X'] = df_Cliente['X'].str.strip(\" \")\n",
    "df_Cliente['Y'] = df_Cliente['Y'].str.replace(\",\", \".\")#.astype(float)\n",
    "df_Cliente['Y'] = df_Cliente['Y'].str.strip(\" \")\n",
    "#obtengo dataframe valores nulos\n",
    "dfn=df_Cliente[df_Cliente['Localidad'].isnull()]\n",
    "dfn.sort_values('ID', inplace= True)\n",
    "dfn1=df_Cliente[df_Cliente['X'].isnull()]\n",
    "dfn1.sort_values('ID', inplace= True)\n",
    "dfn2=df_Cliente[df_Cliente['Y'].isnull()]\n",
    "dfn2.sort_values('ID', inplace= True)\n",
    "df= pd.concat([dfn,dfn1,dfn2], axis=0)\n",
    "#convertirlo en array\n",
    "arrn = df.to_numpy()\n",
    "#Variable de comparacion para normalizar \n",
    "path_csv4 = 'Datasets\\Localidades.csv'\n",
    "dfL5= pd.read_csv(path_csv4, sep=\",\", decimal=\".\") #, on_bad_lines='skip')\n",
    "arr = dfL5.to_numpy()\n",
    "lcentroide_lat=arr[0:,1:2]\n",
    "lcentroide_lon=arr[0:,2:3]\n",
    "llatitud=arrn[0:,8:]\n",
    "llongitud=arrn[0:,7:8]\n",
    "llongitudr=llongitud.flatten().astype(str)\n",
    "llatitudr= llatitud.flatten().astype(str)\n",
    "lcentroide_latr=lcentroide_lat.flatten().astype(str)\n",
    "lcentroide_lonr= lcentroide_lon.flatten().astype(str)\n",
    "lista1= list(llatitudr)\n",
    "lista2= list(llongitudr)\n",
    "lista3= list(lcentroide_latr)\n",
    "lista4= list(lcentroide_lonr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Levenshtein as lev\n",
    "from statistics import mode, multimode\n",
    "\n",
    "def distancefinder(lista1, lista3):\n",
    "\n",
    "    Lista_loc=[]\n",
    "    Lista_pro=[]\n",
    "    Rdistance=[]\n",
    "    Rratio=[]\n",
    "    \n",
    "    for i  in range(len( lista1)):\n",
    "        Str1=lista1[i]\n",
    "        for j in range(len(lista3)):\n",
    "            Str2=lista3[j]\n",
    "            Distance = lev.distance(Str1.lower(),Str2.lower()),\n",
    "            Ratio = lev.ratio(Str1.lower(),Str2.lower())\n",
    "            if Ratio >= 0.50:    \n",
    "                Rdistance.append(Distance)\n",
    "                Rratio.append(Ratio)\n",
    "                loc=arr[(j-1),11:12]\n",
    "                locr=loc.astype(str)\n",
    "                valor1=str(locr)\n",
    "                valor11=valor1.replace(\"['\",\" \")\n",
    "                valor12=valor11.replace(\"']\",\" \")\n",
    "                valor=valor12.strip()\n",
    "                Lista_loc.append(valor)\n",
    "                #Para Provincia\n",
    "                pro=arr[(j-1),13:]\n",
    "                pror=pro.astype(str)\n",
    "                valor2=str(pror)\n",
    "                valor21=valor2.replace(\"['\",\" \")\n",
    "                valor22=valor21.replace(\"']\",\" \")\n",
    "                valor0=valor22.strip()\n",
    "                Lista_pro.append(valor0)\n",
    "        Moda= mode(Lista_loc) \n",
    "                \n",
    "        return Moda#, Lista_loc#, Lista_pro\n",
    "Moda1=distancefinder(lista1, lista3)\n",
    "if Moda1 != \" \":\n",
    "    df_Cliente.fillna({'Localidad': Moda1}, inplace=True)\n",
    "import pandas as pd\n",
    "import Levenshtein as lev\n",
    "from statistics import mode, multimode, median\n",
    "\n",
    "def distancefinder1(lista1, lista3):\n",
    "\n",
    "    Lista_loc=[]\n",
    "    Lista_pro=[]\n",
    "    Rdistance=[]\n",
    "    Rratio=[]\n",
    "    lstr1=[]\n",
    "    lstr2=[]\n",
    "    \n",
    "    for i  in range(len( lista1)):\n",
    "        Str1=lista1[i]\n",
    "        for j in range(len(lista3)):\n",
    "            Str2=lista3[j]\n",
    "            Distance = lev.distance(Str1.lower(),Str2.lower()),\n",
    "            Ratio = lev.ratio(Str1.lower(),Str2.lower())\n",
    "            if Ratio >= 0.80:    \n",
    "                Rdistance.append(Distance)\n",
    "                Rratio.append(Ratio)\n",
    "                loc=arr[(j-1),11:12]\n",
    "                locr=loc.astype(str)\n",
    "                valor1=str(locr)\n",
    "                valor11=valor1.replace(\"['\",\" \")\n",
    "                valor12=valor11.replace(\"']\",\" \")\n",
    "                valor=valor12.strip()\n",
    "                Lista_loc.append(valor)\n",
    "                #Para Provincia\n",
    "                pro=arr[(j-1),13:]\n",
    "                pror=pro.astype(str)\n",
    "                valor2=str(pror)\n",
    "                valor21=valor2.replace(\"['\",\" \")\n",
    "                valor22=valor21.replace(\"']\",\" \")\n",
    "                valor0=valor22.strip()\n",
    "                Lista_pro.append(valor0)\n",
    "                lstr1.append(Str1)\n",
    "                lstr2.append(Str2)\n",
    "        Media1=median(lstr1)\n",
    "        Media2=median(lstr2)\n",
    "        Moda= mode(Lista_loc) \n",
    "\n",
    "                \n",
    "        return Media1#Moda, Lista_loc#, Lista_pro\n",
    "Media1=distancefinder1(lista1, lista3)\n",
    "if Media1 != \" \":\n",
    "    df_Cliente.fillna({'Y': Media1}, inplace=True)\n",
    "\n",
    "#Sustituir media de longitud en X para mantener congruencia en la tabla.\n",
    "import pandas as pd\n",
    "import Levenshtein as lev\n",
    "from statistics import mode, multimode, median\n",
    "\n",
    "def distancefinder1(lista2, lista4):\n",
    "\n",
    "    Lista_loc=[]\n",
    "    Lista_pro=[]\n",
    "    Rdistance=[]\n",
    "    Rratio=[]\n",
    "    lstr1=[]\n",
    "    lstr2=[]\n",
    "    \n",
    "    for i  in range(len( lista2)):\n",
    "        Str1=lista2[i]\n",
    "        for j in range(len(lista4)):\n",
    "            Str2=lista4[j]\n",
    "            Distance = lev.distance(Str1.lower(),Str2.lower()),\n",
    "            Ratio = lev.ratio(Str1.lower(),Str2.lower())\n",
    "            if Ratio >= 0.80:    \n",
    "                Rdistance.append(Distance)\n",
    "                Rratio.append(Ratio)\n",
    "                loc=arr[(j-1),11:12]\n",
    "                locr=loc.astype(str)\n",
    "                valor1=str(locr)\n",
    "                valor11=valor1.replace(\"['\",\" \")\n",
    "                valor12=valor11.replace(\"']\",\" \")\n",
    "                valor=valor12.strip()\n",
    "                Lista_loc.append(valor)\n",
    "                #Para Provincia\n",
    "                pro=arr[(j-1),13:]\n",
    "                pror=pro.astype(str)\n",
    "                valor2=str(pror)\n",
    "                valor21=valor2.replace(\"['\",\" \")\n",
    "                valor22=valor21.replace(\"']\",\" \")\n",
    "                valor0=valor22.strip()\n",
    "                Lista_pro.append(valor0)\n",
    "                lstr1.append(Str1)\n",
    "                lstr2.append(Str2)\n",
    "        Media1=median(lstr1)\n",
    "        Media2=median(lstr2)\n",
    "        Moda= mode(Lista_loc) \n",
    "\n",
    "                \n",
    "        return Media2#Moda, Lista_loc#, Lista_pro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Media2=distancefinder1(lista2, lista4)\n",
    "if Media2 != \" \":\n",
    "    df_Cliente.fillna({'X': Media2}, inplace=True)\n",
    "df_Cliente.dropna(axis=0, inplace=True)\n",
    "#Eliminar los registros nulos en nombres del cliente\n",
    "df_Cliente.dropna(inplace=True)\n",
    "#Tranformacion de tipo de dato formatos nombres de colummas\n",
    "pd.to_numeric(df_Cliente['Edad'], downcast='integer')\n",
    "df_Cliente.columns = ['IdCliente', 'Provincia', 'NombreApellido', 'Domicilio', 'Telefono', 'Edad', 'Localidad','Longitud','Latitud']\n",
    "df_Cliente['NombreApellido']=df_Cliente['NombreApellido'].str.title()\n",
    "df_Cliente['Provincia']=df_Cliente['Provincia'].str.title()\n",
    "df_Cliente['Localidad']=df_Cliente['Localidad'].str.title()\n",
    "df_Cliente['Domicilio']=df_Cliente['Domicilio'].str.title()\n",
    "#Modificacion y formato de datos tabla localidades\n",
    "dfL5.columns = ['Categoria', 'Centroide_Lat', 'Centroide_Lon', 'Departamento_Id ', 'Departamento_Nombre', 'Fuente ', 'IdLocalidad','Localidad_Censal_Id','Localidad_Censal_Nombre', 'Municipio_id','Municipio_Nombre','Localidad_Nombre','Provincia_Id','Provincia_Nombre']\n",
    "dfL5['Categoria']=dfL5['Categoria'].str.title()\n",
    "dfL5['Departamento_Nombre']=dfL5['Departamento_Nombre'].str.title()\n",
    "dfL5['Localidad_Censal_Nombre']=dfL5['Localidad_Censal_Nombre'].str.title()\n",
    "dfL5['Municipio_Nombre']=dfL5['Municipio_Nombre'].str.title()\n",
    "dfL5['Localidad_Nombre']=dfL5['Localidad_Nombre'].str.title()\n",
    "dfL5['Provincia_Nombre']=dfL5['Provincia_Nombre'].str.title()\n",
    "#Normalizacion nombres de acuerdo a la tabla localidad.\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "localidad = dfL5.Localidad_Nombre.value_counts().index\n",
    "local_clientes_unique = df_Cliente.Localidad.unique()\n",
    "normalized = []\n",
    "def get_matches(query,choices):\n",
    "    for i in query:\n",
    "        tuple = process.extractOne(i,choices)\n",
    "        normalized.append(tuple[0])\n",
    "    return normalized\n",
    "local_clientes_correg = get_matches(local_clientes_unique, localidad)\n",
    "mydict = {local_clientes_unique[i]:local_clientes_correg[i] for i in range(0,378)}\n",
    "df_Cliente = df_Cliente.convert_dtypes()\n",
    "df_Cliente[\"LocalidadN\"] = df_Cliente[\"Localidad\"].map(mydict)\n",
    "#borro localidad no nomalizada y renombro los campos\n",
    "df_Cliente.drop(['Localidad'], axis=1, inplace=True)\n",
    "df_Cliente.columns = ['IdCliente', 'Provincia', 'NombreApellido', 'Domicilio', 'Telefono', 'Edad','Longitud','Latitud', 'Localidad']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets\\Venta.csv\n",
      "Datasets\\Venta_Dic2020.csv\n"
     ]
    }
   ],
   "source": [
    "dfL5.fillna({'Municipio_Nombre': 'Sin dato'}, inplace=True)\n",
    "dfL5.fillna({'Municipio_id': 'Sin dato'}, inplace=True)\n",
    "df_Cliente.to_csv(\"Datasets/NormalizacionCliente.csv\")\n",
    "import re\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",  \n",
    "                          \" \",          \n",
    "                          str(dfL5['Departamento_Nombre']))\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",  # Busca las que no sean letras\n",
    "                          \" \",          # Remplaza con espacios\n",
    "                          str(dfL5['Municipio_Nombre']))\n",
    "#Elimina los espacios antes y despues\n",
    "dfL5['Municipio_Nombre'] = dfL5['Municipio_Nombre'].str.strip(\" \")\n",
    "dfL5['Municipio_Nombre'] = dfL5['Departamento_Nombre'].str.strip(\" \")\n",
    "path_csv2= r'Datasets\\Compra.csv'\n",
    "dfC3= pd.read_csv(path_csv2, sep=\",\",decimal=\".\"  )\n",
    "dfC3.drop(['Fecha_Año','Fecha_Mes','Fecha_Periodo'], axis=1, inplace=True)\n",
    "df=dfC3.groupby(by = ['IdProducto','IdProveedor']).Precio.median()\n",
    "valor=df.std()\n",
    "dfC3.fillna({'Precio': valor}, inplace=True)\n",
    "dfC3['Fecha'] = pd.to_datetime(dfC3['Fecha'])\n",
    "dfC3.to_csv(\"Datasets/NormalizacionCompras.csv\")\n",
    "df_UVenta =[]\n",
    "for csv in sorted(glob.glob('Datasets/Vent*.csv')):\n",
    "    print(csv)\n",
    "    df= pd.read_csv(csv, sep=\",\")\n",
    "    df_UVenta.append(df)\n",
    "df_Venta= pd.concat(df_UVenta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_Venta.groupby(by = ['IdProducto']).Precio.median()\n",
    "valor=df.median()\n",
    "valor\n",
    "df_Venta.fillna({'Precio': valor}, inplace=True)\n",
    "df = df_Venta[(df_Venta['Precio'] > 3764.0) & (df_Venta['Precio'] < 50000000.0)]\n",
    "df1 = df_Venta[(df_Venta['Cantidad'] > 3)]\n",
    "df.to_csv(\"Datasets/OurliersPrecioVenta.csv\")\n",
    "df1.to_csv(\"Datasets/OurliersCantidadVenta.csv\")\n",
    "df_Venta= df_Venta.drop(df_Venta[df_Venta['Precio']>3764.0 ].index)\n",
    "df_Venta= df_Venta.drop(df_Venta[df_Venta['Cantidad']>3].index)\n",
    "df_Venta['Fecha'] = pd.to_datetime(df_Venta['Fecha'])\n",
    "df_Venta['Fecha_Entrega'] = pd.to_datetime(df_Venta['Fecha_Entrega'])\n",
    "df_Venta.to_csv(\"Datasets/NormalizacionVentas.csv\")\n",
    "#normalización gasto\n",
    "path_csv3 = r'Datasets\\Gasto.csv'\n",
    "dfG4= pd.read_csv(path_csv3, sep=\",\")\n",
    "dfG4['Fecha'] = pd.to_datetime(dfG4['Fecha'])\n",
    "#Normalizacion Proveedores\n",
    "dfG4.to_csv(\"Datasets/NormalizacionGasto.csv\")\n",
    "path_csv5 = r'Datasets\\Proveedores.csv'\n",
    "dfP5= pd.read_csv(path_csv5, sep=\",\", encoding= 'Latin-1')\n",
    "dfP5.columns = ['IdProveedor', 'NombreProveedor', 'Domicilio', 'Ciudad', 'Provincia', 'Pais','Departamento']\n",
    "dfP5['NombreProveedor']=dfP5['NombreProveedor'].str.title()\n",
    "dfP5['Domicilio']=dfP5['Domicilio'].str.title()\n",
    "dfP5['Ciudad']=dfP5['Ciudad'].str.title()\n",
    "dfP5['Provincia']=dfP5['Provincia'].str.title()\n",
    "dfP5['Pais']=dfP5['Pais'].str.title()\n",
    "dfP5['Departamento']=dfP5['Departamento'].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "localidad = dfL5.Provincia_Nombre.value_counts().index\n",
    "local_clientes_unique = dfP5.Provincia.unique()\n",
    "normalized = []\n",
    "def get_matches(query,choices):\n",
    "    for i in query:\n",
    "        tuple = process.extractOne(i,choices)\n",
    "        normalized.append(tuple[0])\n",
    "    return normalized\n",
    "local_clientes_correg = get_matches(local_clientes_unique, localidad)\n",
    "mydict = {local_clientes_unique[i]:local_clientes_correg[i] for i in range(0,7)}\n",
    "dfP5= dfP5.convert_dtypes()\n",
    "dfP5[\"ProvinciaN\"] =dfP5[\"Provincia\"].map(mydict)\n",
    "dfP5.drop(['Provincia'], axis=1, inplace=True)\n",
    "localidad = dfL5.Departamento_Nombre.value_counts().index\n",
    "local_clientes_unique = dfP5.Departamento.unique()\n",
    "normalized = []\n",
    "def get_matches(query,choices):\n",
    "    for i in query:\n",
    "        tuple = process.extractOne(i,choices)\n",
    "        normalized.append(tuple[0])\n",
    "    return normalized\n",
    "local_clientes_correg = get_matches(local_clientes_unique, localidad)\n",
    "mydict = {local_clientes_unique[i]:local_clientes_correg[i] for i in range(0,7)}\n",
    "dfP5= dfP5.convert_dtypes()\n",
    "dfP5[\"DepartametoN\"] =dfP5[\"Departamento\"].map(mydict)\n",
    "dfP5.drop(['Departamento'], axis=1, inplace=True)\n",
    "dfP5.columns = ['IdProveedor', 'Nombre', 'Domicilio', 'Ciudad','Pais','Provincia','Departamento']\n",
    "dfP5.fillna({'Nombre': 'Sin dato'}, inplace=True)\n",
    "dfP5.to_csv(\"Datasets/NormalizacionProveedores.csv\")\n",
    "#Normalización Sucursal\n",
    "path_csv6 = r'Datasets\\Sucursales.csv'\n",
    "dfS6= pd.read_csv(path_csv6, sep=\";\") \n",
    "dfS6['Sucursal']=dfS6['Sucursal'].str.title()\n",
    "dfS6['Direccion']=dfS6['Direccion'].str.title()\n",
    "dfS6['Localidad']=dfS6['Localidad'].str.title()\n",
    "dfS6['Provincia']=dfS6['Provincia'].str.title()\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",  \n",
    "                          \" \",          \n",
    "                          str(dfS6['Localidad']))\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",  # Busca las que no sean letras\n",
    "                          \" \",          # Remplaza con espacios\n",
    "                          str(dfS6['Provincia']))\n",
    "#Elimina los espacios antes y despues\n",
    "dfS6['Localidad'] = dfS6['Localidad'].str.strip(\" \")\n",
    "dfS6['Provincia'] = dfS6['Provincia'].str.strip(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "localidad = dfL5.Localidad_Nombre.value_counts().index\n",
    "local_clientes_unique =dfS6.Localidad.unique()\n",
    "normalized = []\n",
    "def get_matches(query,choices):\n",
    "    for i in query:\n",
    "        tuple = process.extractOne(i,choices)\n",
    "        normalized.append(tuple[0])\n",
    "    return normalized\n",
    "local_clientes_correg = get_matches(local_clientes_unique, localidad)\n",
    "mydict = {local_clientes_unique[i]:local_clientes_correg[i] for i in range(0,26)}\n",
    "dfS6= dfS6.convert_dtypes()\n",
    "dfS6[\"LocalidadN\"] =dfS6[\"Localidad\"].map(mydict)\n",
    "dfS6.drop(['Localidad'], axis=1, inplace=True)\n",
    "localidad = dfL5.Provincia_Nombre.value_counts().index\n",
    "local_clientes_unique =dfS6.Provincia.unique()\n",
    "normalized = []\n",
    "def get_matches(query,choices):\n",
    "    for i in query:\n",
    "        tuple = process.extractOne(i,choices)\n",
    "        normalized.append(tuple[0])\n",
    "    return normalized\n",
    "local_clientes_correg = get_matches(local_clientes_unique, localidad)\n",
    "mydict = {local_clientes_unique[i]:local_clientes_correg[i] for i in range(0,17)}\n",
    "dfS6= dfS6.convert_dtypes()\n",
    "dfS6[\"ProvinciaN\"] =dfS6[\"Provincia\"].map(mydict)\n",
    "dfS6.drop(['Provincia'], axis=1, inplace=True)\n",
    "dfS6.columns = ['IdSucursal', 'Sucursal', 'Direccion', 'Latitud','Longitud','Localidad','Provincia']\n",
    "dfS6['Latitud'] = dfS6['Latitud'].str.replace(\",\", \".\")#.astype(float)\n",
    "dfS6['Latitud'] = dfS6['Latitud'].str.strip(\" \")\n",
    "dfS6['Longitud'] = dfS6['Longitud'].str.replace(\",\", \".\")#.astype(float)\n",
    "dfS6['Longitud'] = dfS6['Longitud'].str.strip(\" \")\n",
    "dfS6.to_csv(\"Datasets/NormalizacionSucursal.csv\")\n",
    "import mysql.connector\n",
    "conexion1=mysql.connector.connect(host=\"localhost\", user=\"root\", passwd=\"\")#, database=\"bdproyectofinal\")\n",
    "cursor1=conexion1.cursor()\n",
    "cursor1.execute(\"CREATE DATABASE IF NOT EXISTS bdproyectofinal;\")\n",
    "cursor1.execute(\"USE bdproyectofinal;\")\n",
    "cursor1.execute(\"USE bdproyectofinal;\")\n",
    "TablaCliente=\"CREATE TABLE IF NOT EXISTS cliente  (IdCliente INT, NombreApellido VARCHAR(150), Domicilio VARCHAR(250), Telefono VARCHAR(50), Edad INT, RangoEtario VARCHAR (80), IdProvincia INT, IdLocalidad INT, Latitud DOUBLE, Longitud DOUBLE) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_spanish_ci;\"\n",
    "cursor1.execute(TablaCliente)\n",
    "conexion1.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///productos.sqlite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MySQLdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\karen\\OneDrive\\Documentos\\proyecto Individual\\DS-PI-ProyectoIndividual\\limpieza Datos.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karen/OneDrive/Documentos/proyecto%20Individual/DS-PI-ProyectoIndividual/limpieza%20Datos.ipynb#ch0000011?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdeclarative\u001b[39;00m \u001b[39mimport\u001b[39;00m declarative_base\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/karen/OneDrive/Documentos/proyecto%20Individual/DS-PI-ProyectoIndividual/limpieza%20Datos.ipynb#ch0000011?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m \u001b[39mimport\u001b[39;00m Column,Integer,String,DateTime,ForeignKey\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/karen/OneDrive/Documentos/proyecto%20Individual/DS-PI-ProyectoIndividual/limpieza%20Datos.ipynb#ch0000011?line=4'>5</a>\u001b[0m engine \u001b[39m=\u001b[39m create_engine(\u001b[39m'\u001b[39;49m\u001b[39mmysql+mysqldb://deamov:password@127.0.0.1:3306/MySQLTest?charset=utf8\u001b[39;49m\u001b[39m'\u001b[39;49m,echo\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36mcreate_engine\u001b[1;34m(url, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\karen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\util\\deprecations.py:309\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[39mif\u001b[39;00m m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m    303\u001b[0m         _warn_with_version(\n\u001b[0;32m    304\u001b[0m             messages[m],\n\u001b[0;32m    305\u001b[0m             versions[m],\n\u001b[0;32m    306\u001b[0m             version_warnings[m],\n\u001b[0;32m    307\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[0;32m    308\u001b[0m         )\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\karen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\create.py:560\u001b[0m, in \u001b[0;36mcreate_engine\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m    559\u001b[0m             dbapi_args[k] \u001b[39m=\u001b[39m pop_kwarg(k)\n\u001b[1;32m--> 560\u001b[0m     dbapi \u001b[39m=\u001b[39m dialect_cls\u001b[39m.\u001b[39mdbapi(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdbapi_args)\n\u001b[0;32m    562\u001b[0m dialect_args[\u001b[39m\"\u001b[39m\u001b[39mdbapi\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dbapi\n\u001b[0;32m    564\u001b[0m dialect_args\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mcompiler_linting\u001b[39m\u001b[39m\"\u001b[39m, compiler\u001b[39m.\u001b[39mNO_LINTING)\n",
      "File \u001b[1;32mc:\\Users\\karen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sqlalchemy\\dialects\\mysql\\mysqldb.py:163\u001b[0m, in \u001b[0;36mMySQLDialect_mysqldb.dbapi\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdbapi\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[1;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m__import__\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mMySQLdb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'MySQLdb'"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column,Integer,String,DateTime,ForeignKey\n",
    " \n",
    "engine = create_engine('mysql+mysqldb://deamov:password@127.0.0.1:3306/MySQLTest?charset=utf8',echo=True)\n",
    " #echo este parámetro es para imprimir la declaración sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "class User(Base):\n",
    "    __tablename__ = 'users'\n",
    "    \n",
    "    id = Column(Integer, primary_key = Ture)\n",
    "    name = Column(String(40))\n",
    "    orders = relationship('Order')\n",
    " \n",
    "class Product(Base):\n",
    "    __tablename__ = 'products'\n",
    "        \n",
    "    id = Column(Integer, primary_key = Ture)\n",
    "    name = Column(String(40))\n",
    "    orders = relationship('Order')\n",
    "         #Este pedido no es lenguaje ddl, sino para programación orientada a objetos\n",
    " \n",
    "class Order(Base):\n",
    "    __tablename__ = 'orders'\n",
    " \n",
    "    id = Column(Integer,primary_key = True)\n",
    "    otime = Column(DateTime)\n",
    "    uid = Column(Integer, ForeignKey('users.id'))\n",
    "    pid = Column(Integer, ForeignKey('products.id'))\n",
    "         # Definir claves externas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeamoV = User(name = 'DeamoV')\n",
    "session.add(DeamoV)\n",
    "p1 = Product(name = 'p1')\n",
    "session.add(p1)\n",
    "session.commit()\n",
    " \n",
    "'''\n",
    "------\n",
    "'''\n",
    "#DeamoV = session.query(User).filter(User.name=='DeamoV')\n",
    " #Returned es una colección, en la colección está la clase de instancia seleccionada\n",
    "#p1 = session.query(Product).filter(Product.name=='p1')\n",
    " #Producto y Usuario aquí son nombres de clases\n",
    "o1 = Order(uid=p1.id ,pid=p1.id)\n",
    " # Agregó una relación\n",
    "session.add(o1)\n",
    "orders=DeamoV.orders\n",
    " # Esta vez para conseguir esta relación, actualmente solo hay una relación\n",
    "for order in orders:\n",
    "    print(order.id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using URI string without sqlalchemy installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\karen\\OneDrive\\Documentos\\proyecto Individual\\DS-PI-ProyectoIndividual\\limpieza Datos.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/karen/OneDrive/Documentos/proyecto%20Individual/DS-PI-ProyectoIndividual/limpieza%20Datos.ipynb#ch0000054?line=0'>1</a>\u001b[0m dfS6\u001b[39m.\u001b[39;49mto_sql(name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msucursa\u001b[39;49m\u001b[39m'\u001b[39;49m, con\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mengine\u001b[39;49m\u001b[39m'\u001b[39;49m , if_exists\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mappend\u001b[39;49m\u001b[39m'\u001b[39;49m,index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\karen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:2951\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2794\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2795\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2796\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2947\u001b[0m \u001b[39m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   2948\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa:E501\u001b[39;00m\n\u001b[0;32m   2949\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m sql\n\u001b[1;32m-> 2951\u001b[0m \u001b[39mreturn\u001b[39;00m sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[0;32m   2952\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2953\u001b[0m     name,\n\u001b[0;32m   2954\u001b[0m     con,\n\u001b[0;32m   2955\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m   2956\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[0;32m   2957\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   2958\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   2959\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   2960\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   2961\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   2962\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\karen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:688\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[39mif\u001b[39;00m if_exists \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mfail\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mappend\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    686\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mif_exists\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not valid for if_exists\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 688\u001b[0m pandas_sql \u001b[39m=\u001b[39m pandasSQL_builder(con, schema\u001b[39m=\u001b[39;49mschema)\n\u001b[0;32m    690\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(frame, Series):\n\u001b[0;32m    691\u001b[0m     frame \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mto_frame()\n",
      "File \u001b[1;32mc:\\Users\\karen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:754\u001b[0m, in \u001b[0;36mpandasSQL_builder\u001b[1;34m(con, schema)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(con, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    753\u001b[0m     \u001b[39mif\u001b[39;00m sqlalchemy \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 754\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUsing URI string without sqlalchemy installed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    755\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    756\u001b[0m         con \u001b[39m=\u001b[39m sqlalchemy\u001b[39m.\u001b[39mcreate_engine(con)\n",
      "\u001b[1;31mImportError\u001b[0m: Using URI string without sqlalchemy installed."
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "dfS6.to_sql(name='sucursa', con=engine , if_exists='append',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e108a52cce57cf5916b07b5978582f744c8744d6a3baf99b96a1617e350b1888"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
